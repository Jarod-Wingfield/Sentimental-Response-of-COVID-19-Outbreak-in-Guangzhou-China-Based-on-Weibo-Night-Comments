{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 爬取十一月数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from xlutils.copy import copy\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class scrapy_wb():\n",
    "    def __init__(self,start_time,end_time,book_name_xls,sheet_name_xls,keywords):\n",
    "        self.year1 = start_time[0] #开始时间\n",
    "        self.month1 = start_time[1]\n",
    "        self.day1 = start_time[2]\n",
    "        self.h1 = start_time[3]\n",
    "        self.year2 = end_time[0] #结束时间\n",
    "        self.month2 = end_time[1]\n",
    "        self.day2 = end_time[2]\n",
    "        self.h2 = end_time[3]\n",
    "        self.book_name_xls = book_name_xls #填写你想存放excel的路径，没有文件会自动创建\n",
    "        self.sheet_name_xls = sheet_name_xls #sheet表名\n",
    "        self.keywords = keywords #输入你想要的关键字，建议有超话的话加上##，如果结果较少，不加#\n",
    "\n",
    "    def spider(self):\n",
    "        # 创建浏览器（浏览器驱动）\n",
    "        driver = webdriver.Chrome()\n",
    "        # 打开网页\n",
    "        url=\"https://s.weibo.com/weibo?q={}&typeall=1&suball=1&timescope=custom:{}-{:0>2d}-{:0>2d}-{}:{}-{:0>2d}-{:0>2d}-{}&Refer=g&display=0&retcode=6102\".format(\n",
    "            self.keywords, self.year1, self.month1, self.day1, self.h1, self.year2, self.month2, self.day2, self.h2)\n",
    "        driver.get(url=url)\n",
    "        # \"https://s.weibo.com/weibo?q=%s&typeall=1&suball=1&timescope=custom:%s:%s&Refer=g&display=0&retcode=6102\"%(self.keywords,self.start_time,self.end_time)\n",
    "        # 最大化窗口\n",
    "        # 等待时间是用来自主登录微博账号\n",
    "        driver.maximize_window()\n",
    "        for i in range(20):\n",
    "            time.sleep(1)\n",
    "            print('进入等待时间，剩余时间为%s'%(20-i),end='\\r',)\n",
    "        df=pd.DataFrame(np.zeros((1,8),dtype=\"float\"))\n",
    "        df.columns=[\"rid\", \"用户名称\", \"微博内容\", \"微博转发量\",\"微博评论量\",\"微博点赞\",\"发布时间\",\"搜索关键词\"]\n",
    "        if (self.month2-self.month1)==0:        \n",
    "            # 爬一个月的先\n",
    "            self.d1=self.day1\n",
    "            self.d2=self.day1+1\n",
    "        rid = 0\n",
    "        while self.d2<=self.day2:\n",
    "            page=1\n",
    "            URL1=\"https://s.weibo.com/weibo?q={}&typeall=1&suball=1&timescope=custom:{}-{:0>2d}-{:0>2d}-{}:{}-{:0>2d}-{:0>2d}-{}&Refer=g&&page={}\".format(\n",
    "            self.keywords, self.year1, self.month1, self.d1, self.h1, self.year2, self.month2, self.d2, self.h2,page)\n",
    "\n",
    "            driver.get(URL1)\n",
    "            s=driver.find_elements(by=By.XPATH, value='//div[@class=\"m-page\"]//ul[@class=\"s-scroll\"]//li[last()]')[0].get_attribute('textContent')\n",
    "            print(s)\n",
    "            s=s.replace('第','')\n",
    "            s=s.replace('页','')\n",
    "            Page=int(s)\n",
    "\n",
    "            print(self.d1,self.d2,Page)\n",
    "\n",
    "            for p in range(Page):\n",
    "                p=p+1\n",
    "                URL2=\"https://s.weibo.com/weibo?q={}&typeall=1&suball=1&timescope=custom:{}-{:0>2d}-{:0>2d}-{}:{}-{:0>2d}-{:0>2d}-{}&Refer=g&&page={}\".format(\n",
    "                self.keywords, self.year1, self.month1, self.d1, self.h1, self.year2, self.month2, self.d2, self.h2,p)\n",
    "\n",
    "                driver.get(URL2)\n",
    "    \n",
    "                elems=driver.find_elements(by=By.XPATH, value='//div[@class=\"card\"]')\n",
    "                # 一级评论\n",
    "                for i in range(len(elems)):\n",
    "                    try:\n",
    "                        rid = rid + 1\n",
    "                        #用户名\n",
    "                        weibo_username = elems[0].find_elements(by=By.XPATH, value='//a[@class=\"name\"]')[i].text\n",
    "                        #微博内容\n",
    "                        #分为有全文和无全文\n",
    "                        weibo_content = elems[0].find_elements(by=By.XPATH, value='//p[@class=\"txt\"]')[i].text\n",
    "                        shares = elems[0].find_elements(by=By.XPATH, value='//div[@class=\"card-act\"]//ul//li[1]')[i].text\n",
    "                        shares=shares.replace(\"转发\",\"\")\n",
    "                        comments = elems[0].find_elements(by=By.XPATH, value='//div[@class=\"card-act\"]//ul//li[2]')[i].text\n",
    "                        comments=comments.replace(\"评论\",\"\")\n",
    "                        likes = elems[0].find_elements(by=By.XPATH, value='//div[@class=\"card-act\"]//ul//li[3]')[i].text\n",
    "                        if likes=='赞':\n",
    "                            likes='0'\n",
    "                        #发布时间\n",
    "                        weibo_time = elems[0].find_elements(by=By.XPATH, value='//div[@class=\"from\"]//a[1]')[i].text\n",
    "                        # print(\"正在爬取第%s\"%rid)\n",
    "                        \n",
    "                        df=df.append({\"rid\":rid, \"用户名称\":weibo_username, \"微博内容\":weibo_content, \"微博转发量\":shares,\"微博评论量\":comments,\"微博点赞\":likes,\"发布时间\":weibo_time,\"搜索关键词\":self.keywords},ignore_index=True)\n",
    "                        \n",
    "                        if float(likes) > 0:\n",
    "                            button=elems[0].find_elements(by=By.XPATH,value='//div[@class=\"card-act\"]//ul//li[2]//a')[i]\n",
    "                            # print(button.text)\n",
    "                            button.click()\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                # 二级评论\n",
    "                txts=driver.find_elements(by=By.XPATH, value='//div[@class=\"txt\"]//a[@class=\"name\"]')\n",
    "                con=driver.find_elements(by=By.XPATH, value='//div[@class=\"txt\"]')\n",
    "                t=driver.find_elements(by=By.XPATH, value='//div[@class=\"fun\"]//p')\n",
    "                # print(len(txts),len(con),len(t))\n",
    "\n",
    "                for j in range(len(txts)):\n",
    "                    rid = rid + 1\n",
    "                    weibo_username = txts[j].text\n",
    "                    weibo_content=con[j].text.replace(txts[j].text,'')\n",
    "                    weibo_content=weibo_content.replace('：','')\n",
    "                    weibo_time = t[j].text\n",
    "                    df=df.append({\"rid\":rid, \"用户名称\":weibo_username, \"微博内容\":weibo_content, \"微博转发量\":'',\"微博评论量\":'',\"微博点赞\":'',\"发布时间\":weibo_time,\"搜索关键词\":'二级评论'},ignore_index=True)\n",
    "\n",
    "            self.d1=self.d2\n",
    "            self.d2=self.d2+1\n",
    "            # df=df.append({\"rid\":'###', \"用户名称\":'###', \"微博内容\":'###', \"微博转发量\":'###',\"微博评论量\":'###',\"微博点赞\":'###',\"发布时间\":'###',\"搜索关键词\":'###'},ignore_index=True)\n",
    "        \n",
    "        df=df.drop(index=0)\n",
    "        df.to_excel(self.book_name_xls, sheet_name=self.sheet_name_xls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第50页时间，剩余时间为10\n",
      "1 2 50\n",
      "第41页\n",
      "2 3 41\n",
      "第41页\n",
      "3 4 41\n",
      "第49页\n",
      "4 5 49\n",
      "第50页\n",
      "5 6 50\n",
      "第49页\n",
      "6 7 49\n",
      "第50页\n",
      "7 8 50\n",
      "第50页\n",
      "8 9 50\n",
      "第48页\n",
      "9 10 48\n",
      "第50页\n",
      "10 11 50\n",
      "第49页\n",
      "11 12 49\n",
      "第49页\n",
      "12 13 49\n",
      "第50页\n",
      "13 14 50\n",
      "第41页\n",
      "14 15 41\n",
      "第42页\n",
      "15 16 42\n",
      "第50页\n",
      "16 17 50\n",
      "第47页\n",
      "17 18 47\n",
      "第50页\n",
      "18 19 50\n",
      "第46页\n",
      "19 20 46\n",
      "第50页\n",
      "20 21 50\n",
      "第50页\n",
      "21 22 50\n",
      "第47页\n",
      "22 23 47\n",
      "第49页\n",
      "23 24 49\n",
      "第50页\n",
      "24 25 50\n",
      "第50页\n",
      "25 26 50\n",
      "第50页\n",
      "26 27 50\n",
      "第50页\n",
      "27 28 50\n",
      "第50页\n",
      "28 29 50\n",
      "第50页\n",
      "29 30 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wujia\\AppData\\Local\\Temp\\ipykernel_13464\\437040659.py:116: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  df.to_excel(self.book_name_xls, sheet_name=self.sheet_name_xls)\n"
     ]
    }
   ],
   "source": [
    "res=scrapy_wb(start_time = [2022,11,1,14],end_time = [2022,11,30,0],book_name_xls = \"F:/Python_code/Play/wb/covidGZwb_Nov.xls\",sheet_name_xls = '微博数据',keywords = \"广州疫情\")\n",
    "res.spider()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f8b40d688a12481f01eadf7380c47edd8a49484a47dba3db091451640e880c68"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
